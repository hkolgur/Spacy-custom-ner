{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "from common import create_patterns\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOAD SPACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use predefined patterns form common file to make matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matcher = Matcher(nlp.vocab, validate=True)\n",
    "matcher.add(\"PROG_LANG\", None, *create_patterns())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i like python,TENSOR, keras, c++ ,sql,xgboost,python3,golang  C java and golang',\n",
       " {'entities': [(7, 13, 'PROGLANG'),\n",
       "   (14, 20, 'PROGLANG'),\n",
       "   (22, 27, 'PROGLANG'),\n",
       "   (29, 32, 'PROGLANG'),\n",
       "   (34, 37, 'PROGLANG'),\n",
       "   (38, 45, 'PROGLANG'),\n",
       "   (46, 60, 'PROGLANG'),\n",
       "   (62, 63, 'PROGLANG'),\n",
       "   (64, 68, 'PROGLANG'),\n",
       "   (73, 79, 'PROGLANG')]})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_train_data(doc):\n",
    "    detections = [(doc[start:end].start_char, doc[start:end].end_char, 'PROGLANG') for idx, start, end in matcher(doc)]\n",
    "#Unit test to see actual prog language use below line\n",
    "    #detections = [(doc[start:end], 'PROGLANG') for idx, start, end in matcher(doc)]\n",
    "    return (doc.text, {'entities': detections})\n",
    "unit_test_data='i like python,TENSOR, keras, c++ ,sql,xgboost,python3,golang  C java and golang'\n",
    "parse_train_data(nlp(unit_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import docx2txt\n",
    "from collections import Counter\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import PyPDF2\n",
    "from read_resume import create_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read resumes from the folder one by one\n",
    "mypath='C:\\\\Users\\\\Resumes' #enter your path here where you saved the resumes\n",
    "onlyfiles = [os.path.join(mypath, f) for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))]\n",
    "#print(onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Time is : 1.3148770332336426\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "i = 0 \n",
    "TRAIN_DATA=[]\n",
    "while i < len(onlyfiles):\n",
    "  file = onlyfiles[i]\n",
    "  data = create_profile(file,os)\n",
    "  #print(\"testing check 1:\",data)\n",
    "  sample_data = [parse_train_data(d) for d in nlp.pipe(data.split('\\n')) if len(matcher(d)) >= 1]\n",
    "  TRAIN_DATA.append(sample_data)\n",
    "  #print(\"testing check :\",TRAIN_DATA)\n",
    "  i +=1\n",
    "print(\"Total Train Time is :\",time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert list of lists form each resume inot one list of tupples that can be fed to the training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_train = [item for sublist in TRAIN_DATA for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(flat_train))\n",
    "# print(len(flat_train))\n",
    "# print(flat_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "#### Create a blank nlp and add ner to it ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blank_nlp(train_data):\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    ner = nlp.create_pipe(\"ner\")\n",
    "    nlp.add_pipe(ner, last=True)\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "    for _, annotations in train_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            #print('entity hkkkk: is',ent[2])\n",
    "            ner.add_label(ent[2])\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below code is to train the model 1 by one record at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses at iteration 0 - 2020-08-02 05:40:10.902739 {'ner': 158.4156836767297}\n",
      "Losses at iteration 1 - 2020-08-02 05:40:12.872052 {'ner': 19.8173592702547}\n",
      "Losses at iteration 2 - 2020-08-02 05:40:15.112547 {'ner': 0.018498310957170992}\n",
      "Losses at iteration 3 - 2020-08-02 05:40:17.089867 {'ner': 3.088156405792692e-05}\n",
      "Losses at iteration 4 - 2020-08-02 05:40:19.106210 {'ner': 7.338245054324859e-06}\n",
      "Losses at iteration 5 - 2020-08-02 05:40:21.041501 {'ner': 9.9526526231964e-08}\n",
      "Losses at iteration 6 - 2020-08-02 05:40:23.035833 {'ner': 6.144349266683931e-08}\n",
      "Losses at iteration 7 - 2020-08-02 05:40:25.057181 {'ner': 4.616496274321829e-08}\n",
      "Losses at iteration 8 - 2020-08-02 05:40:27.108548 {'ner': 3.54907001641761e-08}\n",
      "Losses at iteration 9 - 2020-08-02 05:40:29.128897 {'ner': 2.719819314363398e-08}\n",
      "Losses at iteration 10 - 2020-08-02 05:40:31.382400 {'ner': 2.2264433337398623e-08}\n",
      "Losses at iteration 11 - 2020-08-02 05:40:33.384735 {'ner': 1.7047931273029152e-08}\n",
      "Losses at iteration 12 - 2020-08-02 05:40:35.411087 {'ner': 1.3905055166222985e-08}\n",
      "Losses at iteration 13 - 2020-08-02 05:40:37.424430 {'ner': 1.1658902211261631e-08}\n",
      "Losses at iteration 14 - 2020-08-02 05:40:39.362724 {'ner': 9.651945860717037e-09}\n",
      "Losses at iteration 15 - 2020-08-02 05:40:41.393078 {'ner': 8.121159097351784e-09}\n",
      "Losses at iteration 16 - 2020-08-02 05:40:43.497481 {'ner': 6.965256646724741e-09}\n",
      "Losses at iteration 17 - 2020-08-02 05:40:45.782007 {'ner': 5.950316263946609e-09}\n",
      "Losses at iteration 18 - 2020-08-02 05:40:48.132574 {'ner': 5.114769807112505e-09}\n",
      "Losses at iteration 19 - 2020-08-02 05:40:50.423102 {'ner': 4.404665869759274e-09}\n",
      "Total Train Time is : 42.05761480331421\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "start=time.time()\n",
    "nlp = create_blank_nlp(flat_train)\n",
    "optimizer = nlp.begin_training()  \n",
    "for i in range(20):\n",
    "    random.shuffle(flat_train)\n",
    "    losses = {}\n",
    "    for text, annotations in flat_train:\n",
    "        nlp.update([text], [annotations], sgd=optimizer, losses=losses)\n",
    "    print(f\"Losses at iteration {i} - {dt.datetime.now()}\", losses)\n",
    "print(\"Total Train Time is :\",time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imporvements\n",
    "#### Use Minibatch  and compounding instead of training one by one record "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.util import minibatch, compounding\n",
    "import random \n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: [W033] Training a new parser or NER using a model with no lexeme normalization table. This may degrade the performance of the model to some degree. If this is intentional or the language you're using doesn't have a normalization table, please ignore this warning. If this is surprising, make sure you have the spacy-lookups-data package installed. The languages with lexeme normalization tables are currently: da, de, el, en, id, lb, pt, ru, sr, ta, th. [language.py:635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses at iteration 0 - 2020-08-02 05:46:30.203927 {'ner': 435.5637432448566}\n",
      "Losses at iteration 1 - 2020-08-02 05:46:30.901393 {'ner': 106.2326471125416}\n",
      "Losses at iteration 2 - 2020-08-02 05:46:31.567837 {'ner': 60.29971016712079}\n",
      "Losses at iteration 3 - 2020-08-02 05:46:32.228275 {'ner': 24.72774334828989}\n",
      "Losses at iteration 4 - 2020-08-02 05:46:32.890717 {'ner': 6.168413556507593}\n",
      "Losses at iteration 5 - 2020-08-02 05:46:33.552161 {'ner': 1.6118480188478725}\n",
      "Losses at iteration 6 - 2020-08-02 05:46:34.219605 {'ner': 5.170136307486152e-05}\n",
      "Losses at iteration 7 - 2020-08-02 05:46:34.875043 {'ner': 3.099047609772414e-06}\n",
      "Losses at iteration 8 - 2020-08-02 05:46:35.536482 {'ner': 1.6470388001993653e-06}\n",
      "Losses at iteration 9 - 2020-08-02 05:46:36.185917 {'ner': 2.4822017472202962e-08}\n",
      "Losses at iteration 10 - 2020-08-02 05:46:36.853361 {'ner': 5.1150892788237106e-06}\n",
      "Losses at iteration 11 - 2020-08-02 05:46:37.599861 {'ner': 2.0419517963845314e-09}\n",
      "Losses at iteration 12 - 2020-08-02 05:46:38.476445 {'ner': 2.0291786640342762e-08}\n",
      "Losses at iteration 13 - 2020-08-02 05:46:39.245957 {'ner': 3.5854030089174e-10}\n",
      "Losses at iteration 14 - 2020-08-02 05:46:39.947426 {'ner': 2.848778633376315e-08}\n",
      "Losses at iteration 15 - 2020-08-02 05:46:40.611871 {'ner': 3.847577724693661e-09}\n",
      "Losses at iteration 16 - 2020-08-02 05:46:41.268307 {'ner': 7.631405468303719e-09}\n",
      "Losses at iteration 17 - 2020-08-02 05:46:41.933751 {'ner': 3.3457306381740717e-09}\n",
      "Losses at iteration 18 - 2020-08-02 05:46:42.596192 {'ner': 4.1402820594634525e-08}\n",
      "Losses at iteration 19 - 2020-08-02 05:46:43.273644 {'ner': 9.826173694748823e-08}\n",
      "Total Train Time is : 14.253191232681274\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "#nlp = create_blank_nlp(TRAIN_DATA)\n",
    "nlp = create_blank_nlp(flat_train)\n",
    "optimizer = nlp.begin_training()\n",
    "for i in range(20):\n",
    "    losses = {}\n",
    "    #batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "    batches = minibatch(flat_train, size=compounding(4.0, 32.0, 1.001))\n",
    "    for batch in batches:\n",
    "        texts, annotations = zip(*batch)\n",
    "        #print('_ - - txts- - - - - - ',texts)\n",
    "        #print('_ - - - - - - - - ',annotations)\n",
    "        nlp.update(\n",
    "            texts,  # batch of texts\n",
    "            annotations,  # batch of annotations\n",
    "            drop=0.1,  # dropout - make it harder to memorise data\n",
    "            sgd=optimizer,\n",
    "            losses=losses,\n",
    "        )\n",
    "    print(f\"Losses at iteration {i} - {dt.datetime.now()} {losses}\")\n",
    "print(\"Total Train Time is :\",time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(\"C:\\\\Users\\\\customnlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the trained Model , perform predicitons and visualize using displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnlp = spacy.load(\"C:\\\\Users\\\\customnlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Involved in requirement gathering, analysis, design, estimation and testing of the assigned tasks in openstack.Implemented rally openstack C# benchmarking tool on the entire cloud environment.Experience in reviewing \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(45deg,orange,red); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       " code for running the troubleshooting test-cases and bug issues.Configuring and managing openstack components such as Keystone, \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(45deg,orange,red); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    sql\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       ", Nova, Neutron, Glance, Swift, \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(45deg,orange,red); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    xgboost\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       ", Heat, \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(45deg,orange,red); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    keras\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       ".\n",
       "<mark class=\"entity\" style=\"background: linear-gradient(45deg,orange,red); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Written\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       " Nova, \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(45deg,orange,red); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Java\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       ", Neutron, \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(45deg,orange,red); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Cinder\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       ", Keystone, Hashboard, Swift, \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(45deg,orange,red); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       " client api to integrate with existing application.Create a strategic architectural design of C platform with networking (VLANs, Firewalls, Load Balancers), Hypervisors (KVM and VMware), workflow and orchestration (Openstack APIS, Smart Cloud Orchestrator), Security (Keystone, lDAP), Inventory and monitoring, licensing, backup/restore.Understanding \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(45deg,orange,red); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       " files in openstack environment and make necessary changes if needed.Involve in the development of the application using \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(45deg,orange,red); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       " 3. 3, HTML5, CSS3, AJAX, \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(45deg,orange,red); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    JSon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(45deg,orange,red); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    JQuery\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#newdata='i like python,TENSOR, keras, c++ , sql, xgboost, python3, golang  C java and golang'\n",
    "newdata1='Involved in requirement gathering, analysis, design, estimation and testing of the assigned tasks in openstack.\\\n",
    "Implemented rally openstack C# benchmarking tool on the entire cloud environment.\\\n",
    "Experience in reviewing python code for running the troubleshooting test-cases and bug issues.\\\n",
    "Configuring and managing openstack components such as Keystone, sql, Nova, Neutron, Glance, Swift, xgboost, Heat, keras.\\\n",
    "Written Nova, Java, Neutron, Cinder, Keystone, Hashboard, Swift, Python client api to integrate with existing application.\\\n",
    "Create a strategic architectural design of C platform with networking (VLANs, Firewalls, Load Balancers), Hypervisors (KVM and VMware), workflow and orchestration (Openstack APIS, Smart Cloud Orchestrator), Security (Keystone, lDAP), Inventory and monitoring, licensing, backup/restore.\\\n",
    "Understanding Python files in openstack environment and make necessary changes if needed.\\\n",
    "Involve in the development of the application using Python 3. 3, HTML5, CSS3, AJAX, JSon and JQuery.'\n",
    "doc = cnlp(newdata1)\n",
    "#colors={'PROGLANG':'lightblue'}\n",
    "colors={'PROGLANG':'radial-gradient(yellow,red)'} #yellow inside to outside red\n",
    "colors={'PROGLANG':'linear-gradient(45deg,orange,red)'}#\n",
    "options={'ents':['PROGLANG'],'colors':colors}\n",
    "displacy.render(doc,style='ent',options=options)\n",
    "#displacy.serve(doc,style='ent',options=options) #open in tab 127.0.0.1:5000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "Total skill count 12\n",
      "[python, sql, xgboost, keras, Written, Java, Cinder, Python, Python, Python, JSon, JQuery]\n",
      "Unique skill count 12\n",
      "{Written, Python, python, sql, Java, Cinder, xgboost, JQuery, Python, Python, JSon, keras}\n"
     ]
    }
   ],
   "source": [
    "print(type(doc.ents))\n",
    "skillcount=list(doc.ents)\n",
    "print(\"Total skill count\",len(skillcount))\n",
    "print(skillcount)\n",
    "uniqueskills=set(skillcount)\n",
    "print(\"Unique skill count\",len(uniqueskills))\n",
    "print(uniqueskills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata2='Job Description :\\\n",
    "- Gather requirements, validate architecture, and create and review high-level and low-level design\\\n",
    "- Provide technology consultation and technical solutions for projects/products\\\n",
    "- Create and review architectural decisions of projects/products\\\n",
    "- Ensure compliance of non-functional attributes (stability, security, availability, performance, etc.) of the product\\\n",
    "to internal standards\\\n",
    "- Guide/provide technical training and influence business/technical decisions\\\n",
    "- Own and execute projects independently from an architectural standpoint What you\\'ll need :\\\n",
    "- A Bachelor- sMaster\\'s degree in Computer Science\\\n",
    "- 6+ years of relevant experience in the technology domain, having worked in Java, Python or similar object-oriented\\\n",
    "language(s)\\\n",
    "- Experience in end-to-end execution and delivery of enterprise grade software\\\n",
    "- Knowledge of design principles, fundamentals of architecture, quality processes and estimation techniques\\\n",
    "- Experience with relational and/or non-relations databases\\\n",
    "- Working proficiency and communication skills in verbal and written English\\\n",
    "- Deep problem-solving abilities and analytical skills to resolve ambiguous requirements\\\n",
    "- Attention to detail and quality, and the ability to work well in and across teams\\\n",
    "- Experience in implementing user interfaces using web-technologies and frameworks, and exposure to delivering highly available,\\\n",
    "scalable large-scale products on cloud platform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(products-, Java, Python)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1=cnlp(newdata2)\n",
    "doc1.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Job Description :- Gather requirements, validate architecture, and create and review high-level and low-level design- Provide technology consultation and technical solutions for projects/\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    products-\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       " Create and review architectural decisions of projects/products- Ensure compliance of non-functional attributes (stability, security, availability, performance, etc.) of the productto internal standards- Guide/provide technical training and influence business/technical decisions- Own and execute projects independently from an architectural standpoint What you'll need :- A Bachelor- sMaster's degree in Computer Science- 6+ years of relevant experience in the technology domain, having worked in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Java\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       " or similar object-orientedlanguage(s)- Experience in end-to-end execution and delivery of enterprise grade software- Knowledge of design principles, fundamentals of architecture, quality processes and estimation techniques- Experience with relational and/or non-relations databases- Working proficiency and communication skills in verbal and written English- Deep problem-solving abilities and analytical skills to resolve ambiguous requirements- Attention to detail and quality, and the ability to work well in and across teams- Experience in implementing user interfaces using web-technologies and frameworks, and exposure to delivering highly available,scalable large-scale products on cloud platform</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc1,style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
